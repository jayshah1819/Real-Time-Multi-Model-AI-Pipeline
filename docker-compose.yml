version: '3'
services:
  triton:
    image: nvcr.io/nvidia/tritonserver:23.09-py3
    command: tritonserver --model-repository=/models
    ports:
      - "8000:8000"  # HTTP
      - "8001:8001"  # gRPC
      - "8002:8002"  # Metrics
    volumes:
      - ./triton_models:/models
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
              
  pipeline:
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - .:/workspace
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    depends_on:
      - triton
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]